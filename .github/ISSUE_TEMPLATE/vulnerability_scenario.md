---
name: New Vulnerability Scenario
about: Propose a new intentional vulnerability to add to the simulation
title: '[VULN] '
labels: vulnerability-scenario
assignees: ''
---

## Vulnerability Overview

**Name**: [e.g., "Insecure Deserialization in Agent Memory"]

**Category**: [e.g., LLM08 - Excessive Agency]

## Description

Describe the vulnerability scenario you want to add.

## Real-World Relevance

Explain where this type of vulnerability has been seen in production AI systems, or why it's a realistic concern.

## Proposed Implementation

### Affected Components

- [ ] Main API (`main.py`)
- [ ] Agent Tools (`agent_tools.py`)
- [ ] Document Upload (`document_upload.py`)
- [ ] Multi-Agent (`multi_agent.py`)
- [ ] Authentication (`auth.py`)
- [ ] RBAC (`rbac.py`)
- [ ] Embeddings (`embeddings.py`)
- [ ] Output Handling (`output_handling.py`)
- [ ] Streaming (`streaming.py`)
- [ ] New module needed

### API Endpoints

What new endpoints would be added?

```
POST /api/example/vulnerable-endpoint
```

### Example Attack

Provide an example of how this vulnerability would be exploited:

```bash
curl -X POST http://localhost:8000/api/example/vulnerable-endpoint \
  -H "Content-Type: application/json" \
  -d '{"malicious": "payload"}'
```

## Learning Objectives

What should users learn from this scenario?

1.
2.
3.

## References

- Link to relevant research papers, blog posts, or documentation
